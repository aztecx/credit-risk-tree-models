{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96db4f8a-9a1e-4be0-ae82-a7b1f86bd84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>target</th>\n",
       "      <th>BadCredit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0       1       6       4      12       5       5       3       4       1   \n",
       "1       2      48       2      60       1       3       2       2       1   \n",
       "2       4      12       4      21       1       4       3       3       1   \n",
       "3       1      42       2      79       1       4       3       4       2   \n",
       "4       1      24       3      49       1       3       3       4       4   \n",
       "\n",
       "   feat_10  ...  feat_17  feat_18  feat_19  feat_20  feat_21  feat_22  \\\n",
       "0       67  ...        0        1        0        0        1        0   \n",
       "1       22  ...        0        1        0        0        1        0   \n",
       "2       49  ...        0        1        0        0        1        0   \n",
       "3       45  ...        0        0        0        0        0        0   \n",
       "4       53  ...        0        1        0        0        0        0   \n",
       "\n",
       "   feat_23  feat_24  target  BadCredit  \n",
       "0        0        1       1          0  \n",
       "1        0        1       2          1  \n",
       "2        1        0       1          0  \n",
       "3        0        1       1          0  \n",
       "4        0        1       2          1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/german_credit_numeric_clean.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c0084e-dbb6-42a4-9e24-0db203968583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 26 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   feat_1     1000 non-null   int64\n",
      " 1   feat_2     1000 non-null   int64\n",
      " 2   feat_3     1000 non-null   int64\n",
      " 3   feat_4     1000 non-null   int64\n",
      " 4   feat_5     1000 non-null   int64\n",
      " 5   feat_6     1000 non-null   int64\n",
      " 6   feat_7     1000 non-null   int64\n",
      " 7   feat_8     1000 non-null   int64\n",
      " 8   feat_9     1000 non-null   int64\n",
      " 9   feat_10    1000 non-null   int64\n",
      " 10  feat_11    1000 non-null   int64\n",
      " 11  feat_12    1000 non-null   int64\n",
      " 12  feat_13    1000 non-null   int64\n",
      " 13  feat_14    1000 non-null   int64\n",
      " 14  feat_15    1000 non-null   int64\n",
      " 15  feat_16    1000 non-null   int64\n",
      " 16  feat_17    1000 non-null   int64\n",
      " 17  feat_18    1000 non-null   int64\n",
      " 18  feat_19    1000 non-null   int64\n",
      " 19  feat_20    1000 non-null   int64\n",
      " 20  feat_21    1000 non-null   int64\n",
      " 21  feat_22    1000 non-null   int64\n",
      " 22  feat_23    1000 non-null   int64\n",
      " 23  feat_24    1000 non-null   int64\n",
      " 24  target     1000 non-null   int64\n",
      " 25  BadCredit  1000 non-null   int64\n",
      "dtypes: int64(26)\n",
      "memory usage: 203.3 KB\n",
      "Index(['feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', 'feat_6', 'feat_7',\n",
      "       'feat_8', 'feat_9', 'feat_10', 'feat_11', 'feat_12', 'feat_13',\n",
      "       'feat_14', 'feat_15', 'feat_16', 'feat_17', 'feat_18', 'feat_19',\n",
      "       'feat_20', 'feat_21', 'feat_22', 'feat_23', 'feat_24', 'target',\n",
      "       'BadCredit'],\n",
      "      dtype='object')\n",
      "\n",
      "BadCredit value counts:\n",
      "BadCredit\n",
      "0    700\n",
      "1    300\n",
      "Name: count, dtype: int64\n",
      "\n",
      "BadCredit proportions:\n",
      "BadCredit\n",
      "0    0.7\n",
      "1    0.3\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Info about this clean dataset\n",
    "df.info()\n",
    "print(df.columns)\n",
    "print(\"\\nBadCredit value counts:\")\n",
    "print(df[\"BadCredit\"].value_counts())\n",
    "print(\"\\nBadCredit proportions:\")\n",
    "print(df[\"BadCredit\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d2f53f-8a30-45f7-be18-10532bda016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape is:  (1000, 24)\n",
      "y Shape is:  (1000,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0       1       6       4      12       5       5       3       4       1   \n",
       "1       2      48       2      60       1       3       2       2       1   \n",
       "2       4      12       4      21       1       4       3       3       1   \n",
       "3       1      42       2      79       1       4       3       4       2   \n",
       "4       1      24       3      49       1       3       3       4       4   \n",
       "\n",
       "   feat_10  ...  feat_15  feat_16  feat_17  feat_18  feat_19  feat_20  \\\n",
       "0       67  ...        1        0        0        1        0        0   \n",
       "1       22  ...        1        0        0        1        0        0   \n",
       "2       49  ...        1        0        0        1        0        0   \n",
       "3       45  ...        1        0        0        0        0        0   \n",
       "4       53  ...        1        1        0        1        0        0   \n",
       "\n",
       "   feat_21  feat_22  feat_23  feat_24  \n",
       "0        1        0        0        1  \n",
       "1        1        0        0        1  \n",
       "2        1        0        1        0  \n",
       "3        0        0        0        1  \n",
       "4        0        0        0        1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features: all feat_1 ... feat_24\n",
    "feature_cols = [col for col in df.columns if col.startswith(\"feat_\")]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"BadCredit\"]\n",
    "\n",
    "print(\"X Shape is: \", X.shape)\n",
    "print(\"y Shape is: \", y.shape)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2deab5c3-88c1-4f92-ba25-28a200c9ca5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data size:  800\n",
      "Testing Data size:  200\n",
      "\n",
      "Train class distribution:\n",
      "BadCredit\n",
      "0    0.7\n",
      "1    0.3\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test class distribution:\n",
      "BadCredit\n",
      "0    0.7\n",
      "1    0.3\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#After creating the df, we split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify = y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training Data size: \",X_train.shape[0])\n",
    "print(\"Testing Data size: \",X_test.shape[0])\n",
    "\n",
    "print(\"\\nTrain class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb45c5e9-9add-437e-82f4-5123b921581f",
   "metadata": {},
   "source": [
    "## Logistic Regression Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbedd039-5be5-468e-9833-571b6c16a646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitc Regression's Accuracy is:  0.77\n",
      "\n",
      "Confusion Matrix of the model:  [[126  14]\n",
      " [ 32  28]]\n",
      "\n",
      "----------------------\n",
      "\n",
      "Classification report(BadCredit = 1 is the positive class): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.797     0.900     0.846       140\n",
      "           1      0.667     0.467     0.549        60\n",
      "\n",
      "    accuracy                          0.770       200\n",
      "   macro avg      0.732     0.683     0.697       200\n",
      "weighted avg      0.758     0.770     0.757       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "accuracy_score,\n",
    "confusion_matrix,\n",
    "classification_report\n",
    ")\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "acc_log = accuracy_score(y_test, y_pred_log)\n",
    "cm_log = confusion_matrix(y_test, y_pred_log)\n",
    "\n",
    "print(\"Logisitc Regression's Accuracy is: \", round(acc_log, 3))\n",
    "print(\"\\nConfusion Matrix of the model: \", cm_log)\n",
    "\n",
    "print(\"\\n----------------------\")\n",
    "print(\"\\nClassification report(BadCredit = 1 is the positive class): \")\n",
    "print(classification_report(y_test, y_pred_log, digits=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178eebeb-e9a5-4cfb-b7d6-5185ec72487f",
   "metadata": {},
   "source": [
    "### Logistic Regression Baseline Model Results\n",
    "\n",
    "- **Train/test split:** 80% train, 20% test (stratified), 1000 total rows.\n",
    "- **Features:** 24 numeric features (`feat_1` ... `feat_24`)\n",
    "- **Target:** `BadCredit` (0 = good, 1 = bad)\n",
    "\n",
    "**Test performance:**\n",
    "\n",
    "- Accuracy: **0.77**\n",
    "- Confusion matrix (rows = true, cols = predicted):\n",
    "\n",
    "\n",
    "**Class 1 (BadCredit = 1) metrics:**\n",
    "\n",
    "- Precision: **0.667**\n",
    "- Recall: **0.467**\n",
    "- F1-score: **0.549**\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- A naive model that always predicts **good** would achieve about **70%** accuracy on this dataset.\n",
    "- Logistic regression improves this to **77%** and correctly flags some bad customers.\n",
    "- However, recall for bad customers (**≈47%**) is relatively low: the model still misses more than half of the truly bad credit cases (32 out of 60).\n",
    "- This makes it a reasonable **baseline**, but there is room for improvement, especially in detecting bad credit risks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3bb6d-84bf-43ca-a89c-404c9cd5a1ae",
   "metadata": {},
   "source": [
    "## Decision Tree  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bb17ed-4699-4167-b452-a0cf3f3b3a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Evaluation**** \n",
      "\n",
      "Decision Tree - Accuracy: 0.72\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[110  30]\n",
      " [ 26  34]]\n",
      "\n",
      "Classification report (BadCredit = 1 is the positive class):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.809     0.786     0.797       140\n",
      "           1      0.531     0.567     0.548        60\n",
      "\n",
      "    accuracy                          0.720       200\n",
      "   macro avg      0.670     0.676     0.673       200\n",
      "weighted avg      0.726     0.720     0.722       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report)\n",
    "\n",
    "#Quick Decsion Tree Model\n",
    "tree_clf = DecisionTreeClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "acc_tree = accuracy_score(y_test, y_pred_tree)\n",
    "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "\n",
    "print(\"*****Evaluation**** \\n\")\n",
    "\n",
    "print(\"Decision Tree - Accuracy:\", round(acc_tree, 3))\n",
    "print(\"\\nConfusion matrix (rows = true, cols = predicted):\")\n",
    "print(cm_tree)\n",
    "\n",
    "print(\"\\nClassification report (BadCredit = 1 is the positive class):\")\n",
    "print(classification_report(y_test, y_pred_tree, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79613e6b-d27c-4cf7-ac8d-27b51f58745c",
   "metadata": {},
   "source": [
    "### Decision Tree Baseline Model Results\n",
    "\n",
    "- Accuracy: **0.72** (slightly above naive baseline of 0.70).\n",
    "- Compared to logistic regression (0.77 accuracy), the tree:\n",
    "  - Improves recall for bad customers (class 1) from **0.467** to **0.567**.\n",
    "  - But reduces precision for bad customers (from **0.667** to **0.531**).\n",
    "  - Increases the number of false positives (good customers flagged as bad).\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- The decision tree learns non-linear rules and is slightly better than a naive\n",
    "  always-good model.\n",
    "- It catches more bad credit cases than logistic regression, but at the cost of\n",
    "  more false alarms and lower overall accuracy.\n",
    "- A single tree is still quite unstable and prone to overfitting, so the next\n",
    "  step is to try ensemble methods (Random Forest, Gradient Boosting) which\n",
    "  usually improve performance and robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702966c8-c37f-436d-8d04-c42e24ba071e",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2264957-00da-4ba1-a7ad-1293eea84ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.755\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[111  29]\n",
      " [ 20  40]]\n",
      "\n",
      "Classification report (BadCredit = 1 is the positive class):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.847     0.793     0.819       140\n",
      "           1      0.580     0.667     0.620        60\n",
      "\n",
      "    accuracy                          0.755       200\n",
      "   macro avg      0.714     0.730     0.720       200\n",
      "weighted avg      0.767     0.755     0.759       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train,y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test,y_pred_rf)\n",
    "cm_rf = confusion_matrix(y_test,y_pred_rf)\n",
    "\n",
    "\n",
    "print(\"Random Forest - Accuracy:\", round(acc_rf, 3))\n",
    "print(\"\\nConfusion matrix (rows = true, cols = predicted):\")\n",
    "print(cm_rf)\n",
    "\n",
    "print(\"\\nClassification report (BadCredit = 1 is the positive class):\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8dbf6-0890-44cc-9e66-18c9b951f1c3",
   "metadata": {},
   "source": [
    "### Model comparison so far\n",
    "\n",
    "Naive baseline (always predict good / BadCredit=0):\n",
    "- Accuracy: **0.70**\n",
    "- Recall for BadCredit=1: **0.00** (never catches bad credit)\n",
    "\n",
    "**Logistic Regression**\n",
    "- Accuracy: **0.77**\n",
    "- BadCredit=1:\n",
    "  - Precision: **0.667**\n",
    "  - Recall: **0.467**\n",
    "  - F1: **0.549**\n",
    "- Interpretation: better than naive, but misses more than half of the bad credit cases.\n",
    "\n",
    "**Decision Tree (unrestricted depth)**\n",
    "- Accuracy: **0.72**\n",
    "- BadCredit=1:\n",
    "  - Precision: **0.531**\n",
    "  - Recall: **0.567**\n",
    "  - F1: **0.548**\n",
    "- Interpretation: catches more bad cases than logistic (higher recall),\n",
    "  but overall accuracy is lower and it produces more false alarms.\n",
    "\n",
    "**Random Forest (200 trees, min_samples_leaf=5, max_features=\"sqrt\", class_weight=\"balanced\")**\n",
    "- Accuracy: **0.755**\n",
    "- BadCredit=1:\n",
    "  - Precision: **0.580**\n",
    "  - Recall: **0.667**\n",
    "  - F1: **0.620**\n",
    "- Interpretation:\n",
    "  - Improves recall for bad credit to about **67%** while keeping a reasonable precision.\n",
    "  - Best F1 for the bad class so far.\n",
    "  - More suitable for a credit risk use-case than a single tree, because it balances\n",
    "    catching bad customers with acceptable false-positive rate.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
